{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, r2_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Sample dataset: Study hours, previous exam scores, and pass/fail labels\n",
        "data = {\n",
        "    'StudyHours': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'PrevExamScore': [30, 40, 45, 50, 60, 65, 70, 75, 80, 85],\n",
        "    'Pass': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]  # 0 = Fail, 1 = Pass\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Features and target variable\n",
        "X = df[['StudyHours', 'PrevExamScore']]\n",
        "y = df['Pass']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-Score: {f1}')\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Initialize the model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Perform 5-fold cross-validation and calculate accuracy for each fold\n",
        "cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Display the accuracy for each fold and the mean accuracy\n",
        "print(f'Cross-validation accuracies: {cv_scores}')\n",
        "print(f'Mean cross-validation accuracy: {np.mean(cv_scores)}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Define multiple scoring metrics\n",
        "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_results = cross_validate(model, X, y, cv=5, scoring=scoring)\n",
        "\n",
        "# Print results for each metric\n",
        "print(f\"Cross-validation Accuracy: {np.mean(cv_results['test_accuracy'])}\")\n",
        "print(f\"Cross-validation Precision: {np.mean(cv_results['test_precision'])}\")\n",
        "print(f\"Cross-validation Recall: {np.mean(cv_results['test_recall'])}\")\n",
        "print(f\"Cross-validation F1-Score: {np.mean(cv_results['test_f1'])}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Sample dataset for regression\n",
        "X_reg = df[['StudyHours']]\n",
        "y_reg = df['PrevExamScore']\n",
        "\n",
        "# Initialize a linear regression model\n",
        "reg_model = LinearRegression()\n",
        "\n",
        "# Perform 5-fold cross-validation using R-squared as the metric\n",
        "cv_scores_r2 = cross_val_score(reg_model, X_reg, y_reg, cv=5, scoring='r2')\n",
        "\n",
        "print(f'Cross-validation R-squared scores: {cv_scores_r2}')\n",
        "print(f'Mean R-squared score: {np.mean(cv_scores_r2)}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy: 1.0\nPrecision: 1.0\nRecall: 1.0\nF1-Score: 1.0\nCross-validation accuracies: [1.  1.  1.  1.  0.5]\nMean cross-validation accuracy: 0.9\nCross-validation Accuracy: 0.9\nCross-validation Precision: 0.9\nCross-validation Recall: 1.0\nCross-validation F1-Score: 0.9333333333333333\nCross-validation R-squared scores: [ 0.52933673  0.88503086 -0.60298929  0.88503086 -1.28939909]\nMean R-squared score: 0.08140201560607148\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1752863455706
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Define forward selection function\n",
        "def forward_selection(X, y):\n",
        "    remaining_features = set(X.columns)\n",
        "    selected_features = []\n",
        "    current_score = 0.0\n",
        "    best_score = 0.0\n",
        "    \n",
        "    while remaining_features:\n",
        "        scores_with_candidates = []\n",
        "        for feature in remaining_features:\n",
        "            features_to_test = selected_features + [feature]\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X[features_to_test], y, test_size=0.2, random_state=42)\n",
        "            model = LinearRegression()\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            score = r2_score(y_test, y_pred)\n",
        "            scores_with_candidates.append((score, feature))\n",
        "        \n",
        "        # Select the feature with the best score\n",
        "        scores_with_candidates.sort(reverse=True)\n",
        "        best_score, best_feature = scores_with_candidates[0]\n",
        "        \n",
        "        if current_score < best_score:\n",
        "            remaining_features.remove(best_feature)\n",
        "            selected_features.append(best_feature)\n",
        "            current_score = best_score\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    return selected_features\n",
        "\n",
        "# Apply forward selection\n",
        "best_features = forward_selection(X, y)\n",
        "print(\"Selected features:\", best_features)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Selected features: ['PrevExamScore']\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1752863912471
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}